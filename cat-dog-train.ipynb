{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc21774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [RUN] Setup Program and Prepare CAT & DOG Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as func\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå (GPU/CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞ Batch Size\n",
    "image_width = image_height = 224\n",
    "batch_size = 64\n",
    "\n",
    "# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "class_number = 2\n",
    "class_labels = [\"cat\", \"dog\"]\n",
    "\n",
    "# Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î Dataset\n",
    "dataset = datasets.ImageFolder(root=\"catdog_dataset/train\", transform=transform)\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á Dataset ‡πÄ‡∏õ‡πá‡∏ô Train (80%) ‡πÅ‡∏•‡∏∞ Validation (20%)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Train ‡πÅ‡∏•‡∏∞ Validation\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î Test Dataset\n",
    "test_dataset = datasets.ImageFolder(root=\"catdog_dataset/test\", transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Dataset\n",
    "print(f\"üìå Train Samples: {len(train_dataset)}, Validation Samples: {len(val_dataset)}, Test Samples: {len(test_dataset)}\")\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å DataLoader\n",
    "def show_images_grid(dataloader, row=8):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:(row*row)]\n",
    "    grid = torchvision.utils.make_grid(images, nrow=row, normalize=True, padding=2)\n",
    "    np_grid = grid.permute(1, 2, 0).numpy()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np_grid)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample Images from DataLoader (Batch size: {len(images)})\")\n",
    "    plt.show()\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å Validation Set\n",
    "show_images_grid(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞ batch size\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å Tiny ImageNet (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏ß)\n",
    "cat_dog_classes = [\"n02124075\", \"n02123159\", \"n02123394\", \"n02123597\", \"n02085620\", \"n02085782\"]\n",
    "\n",
    "# Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î Dataset\n",
    "dataset = datasets.ImageFolder(root=\"tiny-imagenet-200/train\", transform=transform)\n",
    "\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏ß\n",
    "filtered_indices = [i for i, (img, label) in enumerate(dataset) if dataset.classes[label] in cat_dog_classes]\n",
    "filtered_dataset = Subset(dataset, filtered_indices)\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô Train (80%) ‡πÅ‡∏•‡∏∞ Validation (20%)\n",
    "train_size = int(0.8 * len(filtered_dataset))\n",
    "val_size = len(filtered_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(filtered_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Dataset\n",
    "print(f\"üìå Train Samples: {len(train_dataset)}, Validation Samples: {len(val_dataset)}\")\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "def show_images_grid(dataloader, row=8):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:(row*row)]\n",
    "    grid = torchvision.utils.make_grid(images, nrow=row, normalize=True, padding=2)\n",
    "    np_grid = grid.permute(1, 2, 0).numpy()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np_grid)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample Images (Batch size: {len(images)})\")\n",
    "    plt.show()\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Train Set\n",
    "show_images_grid(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "import numpy as np\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# CutMix\n",
    "def rand_bbox(size, lam):\n",
    "    W, H = size[2], size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    \n",
    "    y_a, y_b = y, y[index]\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.RandomErasing(p=0.3),\n",
    "])\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ViT ‡∏û‡∏£‡πâ‡∏≠‡∏° Pretrained Weights\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "model = vit_b_16(weights=weights)\n",
    "model.heads.head = nn.Sequential(\n",
    "    nn.LayerNorm(model.hidden_dim),\n",
    "    nn.Dropout(0.3),  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting\n",
    "    nn.Linear(model.hidden_dim, 2)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ Mixed Precision (fp16)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 50\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Learning Rate Scheduler (Cosine Annealing)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "# SWA (Stochastic Weight Averaging)\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "swa_model = AveragedModel(model)\n",
    "swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", swa_lr=1e-5)\n",
    "\n",
    "# Test the model with fp16\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "with torch.cuda.amp.autocast():  # ‡πÉ‡∏ä‡πâ fp16\n",
    "    output = model(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f923b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "target_loss = 0.0010  # ‡∏Ñ‡πà‡∏≤ loss ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏ô\n",
    "patience = 200  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà‡∏£‡∏≠ ‡∏ñ‡πâ‡∏≤ Validation Loss ‡πÑ‡∏°‡πà‡∏•‡∏î\n",
    "best_val_loss = np.inf\n",
    "wait = 0  # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà Validation Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch[{epoch + 1}/{num_epochs}] training \", end=\" \")\n",
    "    model.train()  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Train Mode\n",
    "\n",
    "    epoch_loss = 0  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ loss ‡∏Ç‡∏≠‡∏á epoch ‡∏ô‡∏µ‡πâ\n",
    "    for data, targets in train_loader:\n",
    "        # Move data and targets to the device (GPU/CPU)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Gradient Explosion)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tracking losses\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ epoch\n",
    "    losses.append(epoch_loss)\n",
    "    print('Train Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "    # ================== Validation Phase ==================\n",
    "    model.eval()  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Eval Mode (‡∏õ‡∏¥‡∏î Dropout/BatchNorm)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradient\n",
    "        for val_data, val_targets in val_loader:\n",
    "            val_data = val_data.to(device)\n",
    "            val_targets = val_targets.to(device)\n",
    "\n",
    "            val_scores = model(val_data)\n",
    "            val_loss += criterion(val_scores, val_targets).item()\n",
    "\n",
    "    val_loss /= len(val_loader)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Validation Loss\n",
    "    val_losses.append(val_loss)\n",
    "    print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "\n",
    "    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤ loss ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á\n",
    "    if epoch_loss < target_loss:\n",
    "        print(f\"‚úÖ Loss ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ {target_loss:.4f}, ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô üöÄ\")\n",
    "        break  # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "\n",
    "    # Early Stopping ‡∏ñ‡πâ‡∏≤ Validation Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        wait = 0  # Reset ‡∏Ñ‡πà‡∏≤ wait\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"‚èπ Early stopping! Validation Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á {patience} epoch ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô\")\n",
    "            break\n",
    "\n",
    "# Plot Training & Validation Loss\n",
    "plt.plot(losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker=\"s\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [RUN] Report Results: ‡πÄ‡∏ã‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_accuracy(loader, model, text=''):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "        print(f\"{text}Got {num_correct}/{num_samples} correct ({accuracy:.2f}%)\")\n",
    "\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def show_images_with_predictions(dataset, model, row=4, device=\"cpu\"):\n",
    "    images, labels = zip(*[dataset[i] for i in range(row * row)])\n",
    "    images = torch.stack(images).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    grid = torchvision.utils.make_grid(images, nrow=row, normalize=True, padding=2)\n",
    "    np_grid = grid.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    if np_grid.shape[-1] == 1:\n",
    "        np_grid = np_grid.squeeze(-1)\n",
    "        cmap = \"gray\"\n",
    "    else:\n",
    "        cmap = None\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np_grid, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Sample Images from Dataset with Predictions\")\n",
    "\n",
    "    for i in range(row * row):\n",
    "        x = (i % row) * (np_grid.shape[1] // row) + (np_grid.shape[1] // row) // 2\n",
    "        y = (i // row) * (np_grid.shape[0] // row) + (np_grid.shape[0] // row) // 2\n",
    "        color = \"green\" if predicted[i] == labels[i] else \"red\"\n",
    "        plt.text(x, y, f\"{class_labels[predicted[i].item()]} ({'‚úî' if predicted[i] == labels[i] else '‚úñ'})\",\n",
    "                 color=color, ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# Run the accuracy check and show results\n",
    "train_acc = check_accuracy(train_loader, model, \"TRAIN dataset accuracy: \")\n",
    "test_acc = check_accuracy(test_loader, model, \"TEST dataset accuracy: \")\n",
    "\n",
    "\n",
    "\n",
    "# Show sample images with predictions\n",
    "show_images_with_predictions(test_dataset, model, 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b93ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "torch.save(model, \"full_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchGEN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
